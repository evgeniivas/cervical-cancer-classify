{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#loading LIBS\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import measure\n",
    "#from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "import mahotas as mh\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#check Folder\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./data\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Init Files id and path\n",
    "TRAIN_DATA = \"./data/train\"\n",
    "TEST_DATA = \"./data/test/\"\n",
    "ADDITIONAL_DATA = \"./data/additional\"\n",
    "types = ['Type_1','Type_2','Type_3']\n",
    "atypes = ['AType_1','AType_2','AType_3']\n",
    "type_1_files = glob(os.path.join(TRAIN_DATA, types[0], \"*.jpg\"))\n",
    "type_1_ids = np.array([s[len(os.path.join(TRAIN_DATA, types[0]))+1:-4] for s in type_1_files])\n",
    "type_2_files = glob(os.path.join(TRAIN_DATA, types[1], \"*.jpg\"))\n",
    "type_2_ids = np.array([s[len(os.path.join(TRAIN_DATA, types[1]))+1:-4] for s in type_2_files])\n",
    "type_3_files = glob(os.path.join(TRAIN_DATA, types[2], \"*.jpg\"))\n",
    "type_3_ids = np.array([s[len(os.path.join(TRAIN_DATA, types[2]))+1:-4] for s in type_3_files])\n",
    "\n",
    "atype_1_files = glob(os.path.join(ADDITIONAL_DATA, atypes[0], \"*.jpg\"))\n",
    "atype_1_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, atypes[0]))+1:-4] for s in atype_1_files])\n",
    "atype_2_files = glob(os.path.join(ADDITIONAL_DATA, atypes[1], \"*.jpg\"))\n",
    "atype_2_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, atypes[1]))+1:-4] for s in atype_2_files])\n",
    "atype_3_files = glob(os.path.join(ADDITIONAL_DATA, atypes[2], \"*.jpg\"))\n",
    "atype_3_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, atypes[2]))+1:-4] for s in atype_3_files])\n",
    "\n",
    "all_types=0\n",
    "all_types = types+atypes\n",
    "\n",
    "\n",
    "test_files = glob(os.path.join(TEST_DATA, \"*.jpg\"))\n",
    "test_ids = np.array([s[len(os.path.join(TEST_DATA)):-4] for s in test_files])\n",
    "all_types.append('Test')\n",
    "\n",
    "type_ids=[type_1_ids,type_2_ids,type_3_ids,atype_1_ids,atype_2_ids,atype_3_ids,test_ids]\n",
    "\n",
    "def get_filename(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image file path from its id and type   \n",
    "    \"\"\"\n",
    "    if image_type == \"Type_1\" or \\\n",
    "        image_type == \"Type_2\" or \\\n",
    "        image_type == \"Type_3\":\n",
    "        data_path = os.path.join(TRAIN_DATA, image_type)\n",
    "    elif image_type == \"Test\":\n",
    "        data_path = TEST_DATA\n",
    "    elif image_type == \"AType_1\" or \\\n",
    "          image_type == \"AType_2\" or \\\n",
    "          image_type == \"AType_3\":\n",
    "        data_path = os.path.join(ADDITIONAL_DATA, image_type)\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    ext = 'jpg'\n",
    "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
    "\n",
    "def get_image_data(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image data as np.array specifying image id and type\n",
    "    \"\"\"\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ROI_TRAIN_DATA = \"./roi/train/\"\n",
    "ROI_ADDITIONAL_DATA = \"./roi/additional/\"\n",
    "ROI_TEST_DATA = \"./roi/test/\"\n",
    "\n",
    "roi_type_1_files = glob(os.path.join(ROI_TRAIN_DATA, types[0], \"*.jpg\"))\n",
    "roi_type_1_ids = np.array([s[len(os.path.join(ROI_TRAIN_DATA, types[0]))+1:-4] for s in roi_type_1_files])\n",
    "roi_type_2_files = glob(os.path.join(ROI_TRAIN_DATA, types[1], \"*.jpg\"))\n",
    "roi_type_2_ids = np.array([s[len(os.path.join(ROI_TRAIN_DATA, types[1]))+1:-4] for s in roi_type_2_files])\n",
    "roi_type_3_files = glob(os.path.join(ROI_TRAIN_DATA, types[2], \"*.jpg\"))\n",
    "roi_type_3_ids = np.array([s[len(os.path.join(ROI_TRAIN_DATA, types[2]))+1:-4] for s in roi_type_3_files])\n",
    "\n",
    "roi_atype_1_files = glob(os.path.join(ROI_ADDITIONAL_DATA, atypes[0], \"*.jpg\"))\n",
    "roi_atype_1_ids = np.array([s[len(os.path.join(ROI_ADDITIONAL_DATA, atypes[0]))+1:-4] for s in roi_atype_1_files])\n",
    "roi_atype_2_files = glob(os.path.join(ROI_ADDITIONAL_DATA, atypes[1], \"*.jpg\"))\n",
    "roi_atype_2_ids = np.array([s[len(os.path.join(ROI_ADDITIONAL_DATA, atypes[1]))+1:-4] for s in roi_atype_2_files])\n",
    "roi_atype_3_files = glob(os.path.join(ROI_ADDITIONAL_DATA, atypes[2], \"*.jpg\"))\n",
    "roi_atype_3_ids = np.array([s[len(os.path.join(ROI_ADDITIONAL_DATA, atypes[2]))+1:-4] for s in roi_atype_3_files])\n",
    "\n",
    "roi_test_files = glob(os.path.join(ROI_TEST_DATA,\"*.jpg\"))\n",
    "roi_test_ids = np.array([s[len(os.path.join(ROI_TEST_DATA)):-4] for s in roi_test_files])\n",
    "\n",
    "roi_type_ids=[roi_type_1_ids,roi_type_2_ids,roi_type_3_ids,roi_atype_1_ids,roi_atype_2_ids,roi_atype_3_ids,roi_test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_zero_size(ids,image_type,i):\n",
    "    if i == True:\n",
    "        start = './data/'\n",
    "    else:\n",
    "        start = './roi/'\n",
    "    \n",
    "    output_list=[]\n",
    "    print(len(ids))\n",
    "    for type_ids in ids:\n",
    "        image_id = type_ids\n",
    "        path=''\n",
    "        ext='.jpg'\n",
    "        additional_path = start+\"additional/\"\n",
    "        train_path = start+\"train/\"\n",
    "        test_path = start+\"test/\"\n",
    "        if image_type == \"Type_1\" or \\\n",
    "            image_type == \"Type_2\" or \\\n",
    "            image_type == \"Type_3\":\n",
    "            path = train_path+str(image_type)+'/'+str(image_id)+ext\n",
    "        elif image_type == \"AType_1\" or \\\n",
    "            image_type == \"AType_2\" or \\\n",
    "            image_type == \"AType_3\":\n",
    "            path = additional_path+str(image_type)+'/'+str(image_id)+ext\n",
    "        elif image_type == \"Test\":\n",
    "            path = test_path+str(image_id)+ext\n",
    "            \n",
    "        if os.stat(str(path)).st_size != 0:\n",
    "            output_list.append(image_id)\n",
    "    print(len(output_list))\n",
    "    print(\"\")\n",
    "    return output_list\n",
    "            \n",
    "for i in xrange(0,len(type_ids)):\n",
    "    for j in xrange(0,len(all_types)):\n",
    "        if(i==j):\n",
    "            type_ids[i]=check_zero_size(type_ids[i],all_types[j],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/chiszpanski/intel-mobileodt-cervical-cancer-screening/non-cervix-images\n",
    "def check_no_cervix_image(ids,image_type):\n",
    "    no_cervix_ATYPE_1 = ['746','2030','4065','4702','4706','6360']\n",
    "    no_cervix_ATYPE_2 = ['1813','3086']\n",
    "    print(image_type)\n",
    "    print(len(ids))\n",
    "    if image_type =='AType_1':\n",
    "        ids = filter(lambda v:v not in no_cervix_ATYPE_1,ids)\n",
    "    elif image_type =='AType_2':\n",
    "        ids = filter(lambda z:z not in no_cervix_ATYPE_2,ids)\n",
    "    print(len(ids))\n",
    "    print(\"\")\n",
    "    return ids\n",
    "    \n",
    "for i in xrange(0,len(type_ids)):\n",
    "    for j in xrange(0,len(all_types)):\n",
    "        if(i==j):\n",
    "            type_ids[i]=check_no_cervix_image(type_ids[i],all_types[j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_counts():\n",
    "    for i in xrange(0,len(type_ids)):\n",
    "        print len(type_ids[i])\n",
    "        print len(roi_type_ids[i])\n",
    "        print (\"\")\n",
    "\n",
    "check_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for i in xrange(0,len(type_ids)):\n",
    "#    for item in type_ids[i]:\n",
    "#        if item not in roi_type_ids[i]:\n",
    "#            type_ids[i].remove(item)\n",
    "\n",
    "\n",
    "for j in xrange(0,len(type_ids)):\n",
    "    type_ids[j] = filter(lambda v:v not in roi_type_ids[j],type_ids[j])\n",
    "    \n",
    "check_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def maxHist(hist):\n",
    "    \"\"\"\n",
    "    Method to find max area value in histogram \n",
    "    https://www.youtube.com/watch?v=g8bSdXCG-lA\n",
    "    https://www.youtube.com/watch?v=VNbkzsnllsU \n",
    "    \"\"\"\n",
    "    maxArea = (0, 0, 0)\n",
    "    height = []\n",
    "    position = []\n",
    "    for i in range(len(hist)):\n",
    "        if (len(height) == 0):\n",
    "            if (hist[i] > 0):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "        else: \n",
    "            if (hist[i] > height[-1]):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "            elif (hist[i] < height[-1]):\n",
    "                while (height[-1] > hist[i]):\n",
    "                    maxHeight = height.pop()\n",
    "                    area = maxHeight * (i-position[-1])\n",
    "                    if (area > maxArea[0]):\n",
    "                        maxArea = (area, position[-1], i)\n",
    "                    last_position = position.pop()\n",
    "                    if (len(height) == 0):\n",
    "                        break\n",
    "                position.append(last_position)\n",
    "                if (len(height) == 0):\n",
    "                    height.append(hist[i])\n",
    "                elif(height[-1] < hist[i]):\n",
    "                    height.append(hist[i])\n",
    "                else:\n",
    "                    position.pop()    \n",
    "    while (len(height) > 0):\n",
    "        maxHeight = height.pop()\n",
    "        last_position = position.pop()\n",
    "        area =  maxHeight * (len(hist) - last_position)\n",
    "        if (area > maxArea[0]):\n",
    "            maxArea = (area, len(hist), last_position)\n",
    "    return maxArea\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def maxRect(img):\n",
    "    \"\"\"\n",
    "    Method to find max Rectangle in image (thresholded)\n",
    "    \"\"\"\n",
    "    maxArea = (0, 0, 0)\n",
    "    addMat = np.zeros(img.shape)\n",
    "    for r in range(img.shape[0]):\n",
    "        if r == 0:\n",
    "            addMat[r] = img[r]\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "        else:\n",
    "            addMat[r] = img[r] + addMat[r-1]\n",
    "            addMat[r][img[r] == 0] *= 0\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "    return (int(maxArea[3]+1-maxArea[0]/abs(maxArea[1]-maxArea[2])), maxArea[2], maxArea[3], maxArea[1], maxArea[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cropCircle(img):\n",
    "    \"\"\"\n",
    "    Method to crop image => remove circular frames\n",
    "    \"\"\"\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "    \n",
    "    \n",
    "    img = cv2.resize(img, dsize=tile_size)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY);\n",
    "    \n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    _, contours, _ = cv2.findContours(thresh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    main_contour = sorted(contours, key = cv2.contourArea, reverse = True)[0]\n",
    "    ff = np.zeros((gray.shape[0],gray.shape[1]), 'uint8') \n",
    "    cv2.drawContours(ff, main_contour, -1, 1, 2)\n",
    "    \n",
    "    ff_mask = np.zeros((gray.shape[0]+2,gray.shape[1]+2), 'uint8')\n",
    "    cv2.floodFill(ff, ff_mask,(int(gray.shape[1]/2), int(gray.shape[0]/2)), 1)\n",
    "    \n",
    "    rect = maxRect(ff)\n",
    "    img_crop = img[min(rect[0],rect[2]):max(rect[0],rect[2]), min(rect[1],rect[3]):max(rect[1],rect[3])]\n",
    "    cv2.rectangle(ff,(min(rect[1],rect[3]),min(rect[0],rect[2])),(max(rect[1],rect[3]),max(rect[0],rect[2])),3,2)\n",
    "    \n",
    "    return img_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Circle(img):\n",
    "    \"\"\"\n",
    "    Method to crop image => remove circular frames\n",
    "    \"\"\"\n",
    "    #fig, axes = plt.subplots(2, 4,figsize=(25,17))\n",
    "    #axes[0,0].imshow(img)\n",
    "    #axes[0,0].set_title('IMG')\n",
    "    #axes[0,0].axis('off')\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "    \n",
    "    img = cv2.resize(img, dsize=tile_size)\n",
    "    #axes[0,1].imshow(img)\n",
    "    #axes[0,1].set_title('SIZE')\n",
    "    #axes[0,1].axis('off')\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY);\n",
    "    #axes[0,2].imshow(gray)\n",
    "    #axes[0,2].set_title(\"GRAY\")\n",
    "    #axes[0,2].axis('off')\n",
    "    \n",
    "    \n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    #axes[0,3].imshow(thresh)\n",
    "    #axes[0,3].set_title('THRESH')\n",
    "    #axes[0,3].axis('off')\n",
    "    \n",
    "    _, contours, _ = cv2.findContours(thresh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    main_contour = sorted(contours, key = cv2.contourArea, reverse = True)[0]\n",
    "    ff = np.zeros((gray.shape[0],gray.shape[1]), 'uint8') \n",
    "    cv2.drawContours(ff, main_contour, -1, 1, 2)\n",
    "    #axes[1,0].imshow(ff)\n",
    "    #axes[1,0].set_title('CONTOURS')\n",
    "    #axes[1,0].axis('off')\n",
    "    \n",
    "    \n",
    "    ff_mask = np.zeros((gray.shape[0]+2,gray.shape[1]+2), 'uint8')\n",
    "    cv2.floodFill(ff, ff_mask,(int(gray.shape[1]/2), int(gray.shape[0]/2)), 1)\n",
    "    #axes[1,1].imshow(ff)\n",
    "    #axes[1,1].set_title('FILLED')\n",
    "    #axes[1,1].axis('off')\n",
    "    \n",
    "    rect = maxRect(ff)\n",
    "    img_crop = img[min(rect[0],rect[2]):max(rect[0],rect[2]), min(rect[1],rect[3]):max(rect[1],rect[3])]\n",
    "    cv2.rectangle(ff,(min(rect[1],rect[3]),min(rect[0],rect[2])),(max(rect[1],rect[3]),max(rect[0],rect[2])),3,2)\n",
    "    #axes[1,2].imshow(ff)\n",
    "    #axes[1,2].set_title('RECTANGLE')\n",
    "    #axes[1,2].axis('off')\n",
    "    #axes[1,3].imshow(img_crop)\n",
    "    #axes[1,3].set_title('FINAL')\n",
    "    #axes[1,3].axis('off')\n",
    "    return img_crop\n",
    "    #return img_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_image = get_image_data(type_1_ids[1],all_types[0])\n",
    "q=Circle(new_image)\n",
    "plt.imshow(q)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Initial delineation of the cervix\n",
    "def Ra_space(img, Ra_ratio, a_threshold):\n",
    "    \"\"\"\n",
    "    Method to find ROI (Region of Interest)\n",
    "    Change colormap to LAB\n",
    "    A-channel - the higher value = the redder the pixel color\n",
    "    R - distance of a pixel from the image center. (spartial information => continuous regions)\n",
    "    \"\"\"\n",
    "    imgLab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB);\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    Ra = np.zeros((w*h, 2))\n",
    "    for i in xrange(w):\n",
    "        for j in xrange(h):\n",
    "            R = math.sqrt((w/2-i)*(w/2-i) + (h/2-j)*(h/2-j))\n",
    "            Ra[i*h+j, 0] = R\n",
    "            Ra[i*h+j, 1] = min(imgLab[i][j][1], a_threshold)\n",
    "            \n",
    "    Ra[:,0] /= max(Ra[:,0])\n",
    "    Ra[:,0] *= Ra_ratio\n",
    "    Ra[:,1] /= max(Ra[:,1])\n",
    "\n",
    "    return Ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The image is separated next into two clusters in the 2-D (a-R) feature space;\n",
    "#Gaussian mixture modeling, initialized by a K-means\n",
    "def segmentation(img_real,image_id,image_type):\n",
    "        \n",
    "    print(image_id, image_type)\n",
    "        \n",
    "    #r,g,b = img_real.transpose(2,0,1)\n",
    "    #r12 = mh.gaussian_filter(r,48.)\n",
    "    #g12 = mh.gaussian_filter(g,48.)\n",
    "    #b12 = mh.gaussian_filter(b,48.)\n",
    "    #img=mh.as_rgb(r12,g12,b12)\n",
    "            \n",
    "    \n",
    "    #plt.figure(figsize=(20,15))\n",
    "    #plt.subplot(181)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(img_real)\n",
    "    img = cropCircle(img_real)\n",
    "    res = img.copy()\n",
    "\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "        \n",
    "    Ra = Ra_space(img,0.001,150)\n",
    "    print(Ra.shape)\n",
    "        \n",
    "    a_channel = np.reshape(Ra[:,1], (w,h))\n",
    "    r_channel = np.reshape(Ra[:,0], (w,h))\n",
    "    third_channel = np.ones_like(a_channel)\n",
    "    third_channel[third_channel>0] = 255\n",
    "    result_ra = np.dstack((a_channel, r_channel, third_channel))\n",
    "    #plt.subplot(182)\n",
    "    plt.axis('off')\n",
    "    plt.set_cmap('Reds')\n",
    "    plt.imshow(r_channel) \n",
    "\n",
    "    gmm = GaussianMixture(n_components = 2, covariance_type = 'diag', random_state = 0, init_params = 'kmeans')\n",
    "    image_array_sample = shuffle(Ra, random_state=0)\n",
    "    gmm.fit(image_array_sample)\n",
    "    labels = gmm.predict(Ra)\n",
    "    labels += 1\n",
    "    \n",
    "    # The cluster that has the highest a-mean is selected.\n",
    "    labels_2D = np.reshape(labels, (w,h))\n",
    "    \n",
    "    \n",
    "    #plt.subplot(183)\n",
    "    #plt.axis('off')\n",
    "    #plt.set_cmap('Reds')\n",
    "    #plt.imshow(labels_2D)\n",
    "    gg_labels_regions = measure.regionprops(labels_2D, intensity_image = a_channel)\n",
    "    gg_intensity = [prop.mean_intensity for prop in gg_labels_regions]\n",
    "    cervix_cluster = gg_intensity.index(max(gg_intensity)) + 1\n",
    "    \n",
    "\n",
    "    mask = np.zeros((w * h,1),'uint8')\n",
    "    mask[labels==cervix_cluster] = 255\n",
    "    mask_2D = np.reshape(mask, (w,h))\n",
    "\n",
    "    cc_labels = measure.label(mask_2D, background=0)\n",
    "    regions = measure.regionprops(cc_labels)\n",
    "    areas = [prop.area for prop in regions]\n",
    "\n",
    "    regions_label = [prop.label for prop in regions]\n",
    "    largestCC_label = regions_label[areas.index(max(areas))]\n",
    "    mask_largestCC = np.zeros((w,h),'uint8')\n",
    "    mask_largestCC[cc_labels==largestCC_label] = 255\n",
    "\n",
    "    img_masked = img.copy()\n",
    "    img_masked[mask_largestCC==0] = (0,0,0)\n",
    "    img_masked_gray = cv2.cvtColor(img_masked, cv2.COLOR_RGB2GRAY);\n",
    "            \n",
    "    _,thresh_mask = cv2.threshold(img_masked_gray,0,255,0)\n",
    "    #plt.subplot(184)\n",
    "    #plt.axis(\"off\")\n",
    "    #plt.imshow(img_masked)\n",
    "    \n",
    "    #plt.subplot(185)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(thresh_mask)\n",
    "    kernel = np.ones((11,11), np.uint8)\n",
    "    thresh_mask = cv2.dilate(thresh_mask, kernel, iterations = 1)\n",
    "    thresh_mask = cv2.erode(thresh_mask, kernel, iterations = 2)\n",
    "    _, contours_mask, _ = cv2.findContours(thresh_mask.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    main_contour = sorted(contours_mask, key = cv2.contourArea, reverse = True)[0]\n",
    "                    \n",
    "    x,y,w,h = cv2.boundingRect(main_contour)\n",
    "    #roi = img_real[y:y+h,x:x+w]\n",
    "    roi = img[y:y+h,x:x+w]\n",
    "        \n",
    "        \n",
    "    image = img.copy()\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),255,3)\n",
    "                            \n",
    "    #plt.subplot(186)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(image)\n",
    "    #plt.subplot(187)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(roi)\n",
    "            \n",
    "           \n",
    "    roi = cv2.cvtColor(roi,cv2.COLOR_BGR2RGB)\n",
    "    ext='.jpg'\n",
    "    \n",
    "    '''\n",
    "    types = ['Type_1','Type_2','Type_3']\n",
    "    atypes = ['AType_1','AType_2','AType_3']\n",
    "    test = 'Test'\n",
    "    print roi.shape[0], \" \", roi.shape[1]\n",
    "    if image_type in types:\n",
    "        cv2.imwrite('./roi/train/'+str(image_type)+'/'+str(image_id)+ext,roi)\n",
    "    elif image_type in atypes:\n",
    "        cv2.imwrite('./roi/additional/'+str(image_type)+'/'+str(image_id)+ext,roi)\n",
    "    elif image_type == test:\n",
    "        cv2.imwrite('./roi/test/'+str(image_id)+ext,roi)\n",
    "    '''    \n",
    "for i in xrange(0,1):#len(all_types)-1,len(all_types)):\n",
    "    for q in xrange(144,145):#len(type_ids[i])):\n",
    "        img_id = type_ids[i][q]\n",
    "        img_type = all_types[i]\n",
    "        img = get_image_data(img_id,img_type)\n",
    "        segmentation(img,img_id,img_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(get_image_data(type_ids[0][2],all_types[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_roi_filename(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image file path from its id and type   \n",
    "    \"\"\"\n",
    "    if image_type == \"Type_1\" or \\\n",
    "        image_type == \"Type_2\" or \\\n",
    "        image_type == \"Type_3\":\n",
    "        data_path = os.path.join(ROI_TRAIN_DATA, image_type)\n",
    "    elif image_type == \"Test\":\n",
    "        data_path = ROI_TEST_DATA\n",
    "    elif image_type == \"AType_1\" or \\\n",
    "          image_type == \"AType_2\" or \\\n",
    "          image_type == \"AType_3\":\n",
    "        data_path = os.path.join(ROI_ADDITIONAL_DATA, image_type)\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    ext = 'jpg'\n",
    "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
    "\n",
    "def get_roi_image_data(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image data as np.array specifying image id and type\n",
    "    \"\"\"\n",
    "    fname = get_roi_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "for i in xrange(0,len(roi_type_ids)):\n",
    "    for j in xrange(0,len(all_types)):\n",
    "        if(i==j):\n",
    "            roi_type_ids[i]=check_zero_size(roi_type_ids[i],all_types[j],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def chist(img):\n",
    "    img = img // 64\n",
    "    r,g,b = img.transpose((2,0,1))\n",
    "    pixels = 1 * r + 4 * b + 16 * g\n",
    "    hist = np.bincount(pixels.ravel(),minlength = 64)\n",
    "    hist = hist.astype(float)\n",
    "    hist = np.log1p(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_features(img,img_id,img_type):\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    if w>4 and h>4: \n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        surf = cv2.xfeatures2d.SURF_create()\n",
    "            \n",
    "        print(img_id, img_type)\n",
    "\n",
    "        haralick = np.ravel(mh.features.haralick(img))\n",
    "        color_hist = chist(img)\n",
    "        pftas=mh.features.pftas(img)\n",
    "        \n",
    "        img = cv2.cvtColor( img, cv2.COLOR_RGB2GRAY )\n",
    "        _ , sift_desc = sift.detectAndCompute(img,None)\n",
    "        _ , surf_desc = surf.detectAndCompute(img,None)\n",
    "        lbp = mh.features.lbp(img,radius=8,points=6)\n",
    "        return [img_id,img_type,haralick,color_hist,pftas,sift_desc,surf_desc,lbp]\n",
    "\n",
    "\n",
    "img_features = []\n",
    "img_ids = []\n",
    "img_types = []\n",
    "img_haralick = []\n",
    "img_chist = []\n",
    "img_pftas = []\n",
    "img_sift = []\n",
    "img_surf = []\n",
    "img_lbp = []\n",
    "\n",
    "for q in xrange(len(roi_type_ids)-1,len(roi_type_ids)):\n",
    "    for u in xrange(0,len(roi_type_ids[q])):\n",
    "        print str((float(u)/float(len(roi_type_ids[q])))*100)+'%'\n",
    "        img = get_roi_image_data(roi_type_ids[q][u],all_types[q])\n",
    "        name = roi_type_ids[q][u]\n",
    "        if q == 6:\n",
    "            img_type = 'Test'\n",
    "        else:\n",
    "            h = q % 3\n",
    "            img_type = all_types[h]\n",
    "        \n",
    "        features = make_features(img,name,img_type)\n",
    "        if features:\n",
    "            img_ids.append(features[0])\n",
    "            img_types.append(features[1])\n",
    "            img_haralick.append(features[2])\n",
    "            img_chist.append(features[3])\n",
    "            img_pftas.append(features[4])\n",
    "            img_sift.append(features[5])\n",
    "            img_surf.append(features[6])\n",
    "            img_lbp.append(features[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_dims(desc,name):\n",
    "    size_2 = 0\n",
    "    size_1 = 0\n",
    "    size_0 = 0\n",
    "    none_ = 0\n",
    "\n",
    "    for i in xrange(0,len(desc)):\n",
    "        if desc[i] is not None:\n",
    "            if desc[i].ndim == 0:\n",
    "                size_0+=1\n",
    "            elif desc[i].ndim == 1:\n",
    "                size_1+=1\n",
    "            elif desc[i].ndim == 2:\n",
    "                size_2+=1\n",
    "        else:\n",
    "            none_+=1\n",
    "            \n",
    "    print str(name)+\" DIM = 2: \"+str(size_2)\n",
    "    print str(name)+\" DIM = 1: \"+str(size_1)\n",
    "    print str(name)+\" DIM = 0: \"+str(size_0)\n",
    "    print str(name)+\" NONE \"+str(none_)\n",
    "    print \"FULL LENGTH: \"+str(len(desc))+\" | SUM: \"+str(size_2+size_1+size_0+none_)+\" | WITHOUT NULL \"+str(size_2+size_1+size_0)\n",
    "    print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "check_dims(img_pftas,'PFTAS')\n",
    "check_dims(img_chist,'CHIST')\n",
    "check_dims(img_haralick,'HARALICK')\n",
    "check_dims(img_sift,'SIFT')\n",
    "check_dims(img_surf,'SURF')\n",
    "check_dims(img_lbp,'LBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def filter_desc(desc):\n",
    "    result = filter(lambda x:x is not None,desc )\n",
    "    return result\n",
    "\n",
    "def fix_desc(desc):\n",
    "    result = []\n",
    "    n = len(desc[0][0])\n",
    "    for i in desc:\n",
    "        if i is not None:\n",
    "            result.append(i)\n",
    "        else:\n",
    "            result.append([0 for i in xrange(0,n)])        \n",
    "    return result\n",
    "    \n",
    "\n",
    "def concatenate_desc(desc):\n",
    "    result = np.concatenate(desc)\n",
    "    return result\n",
    "\n",
    "def check_desc_len(desc,n):\n",
    "    filter_desc = filter(lambda x: x is not None,desc )\n",
    "    result = np.concatenate(filter_desc)\n",
    "    result = result[::n]\n",
    "    print len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "check_desc_len(img_sift,1)\n",
    "check_desc_len(img_surf,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "def bow(desc,n,k,name,check=True):\n",
    "    filtered_desc = filter_desc(desc)\n",
    "    \n",
    "    if check:\n",
    "        desc = fix_desc(desc)\n",
    "    \n",
    "    concatenated = concatenate_desc(filtered_desc)\n",
    "    #concatenated = np.load('./concatenate_bow/'+str(name)+'.npy')\n",
    "    concatenated = concatenated[::n]\n",
    "    print len(concatenated)\n",
    "\n",
    "    km = KMeans(k)\n",
    "    \n",
    "    km.fit(concatenated)\n",
    "    \n",
    "    #joblib.dump(km, './models/'+str(name)+'.pkl')\n",
    "    \n",
    "    result = []\n",
    "    for d in desc:\n",
    "        c = km.predict(d)\n",
    "        result.append(\n",
    "            np.array([np.sum(c==ci) for ci in xrange(k)])\n",
    "        )\n",
    "    \n",
    "    result = np.array(result,dtype=float)\n",
    "    print 'Result len '+str(len(result))\n",
    "    return result\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "def bow(desc,k,name,check=True):\n",
    "    desc= desc\n",
    "    if check:\n",
    "        desc = fix_desc(desc)\n",
    "\n",
    "    km = joblib.load('./models/'+str(name)+'.pkl')\n",
    "    result = []\n",
    "    for d in desc:\n",
    "        c = km.predict(d)\n",
    "        result.append(\n",
    "            np.array([np.sum(c==ci) for ci in xrange(k)],dtype=float)\n",
    "        )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_surf = bow(img_surf,256,'SURF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_sift = bow(img_sift,256,'SIFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_surf = bow(img_surf,8,256,'SURF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_sift = bow(img_sift,5,256,'SIFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print len(img_surf),len(img_sift),len(img_haralick),len(img_chist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#SAVE FEATURES TO FILES\n",
    "img_ids = np.array(img_ids)\n",
    "img_types = np.array(img_types)\n",
    "img_chist = np.array(img_chist)\n",
    "img_haralick = np.array(img_haralick)\n",
    "img_pftas = np.array(img_pftas)\n",
    "img_sift = np.array(img_sift)\n",
    "img_surf = np.array(img_surf)\n",
    "img_lbp = np.array(img_lbp)\n",
    "\n",
    "def save_feature_to_file(feature,name):\n",
    "    path = './features/'+str(name)+'.npy'\n",
    "    np.save(path,feature)\n",
    "    \n",
    "\n",
    "save_feature_to_file(img_ids,'id')\n",
    "save_feature_to_file(img_types,'type')\n",
    "save_feature_to_file(img_chist,'chist')\n",
    "save_feature_to_file(img_haralick,'haralick')\n",
    "save_feature_to_file(img_pftas,'pftas')\n",
    "save_feature_to_file(img_sift,'sift')\n",
    "save_feature_to_file(img_surf,'surf')\n",
    "save_feature_to_file(img_lbp,'lbp')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#OPEN FEATURES FROM FILES\n",
    "def open_features_from_files(name):\n",
    "    path = './features/'+str(name)+'.npy'\n",
    "    x = np.load(path)\n",
    "    return np.array(x)\n",
    "\n",
    "img_ids = open_features_from_files('id')\n",
    "img_types = open_features_from_files('type')\n",
    "img_chist = open_features_from_files('chist')\n",
    "img_haralick = open_features_from_files('haralick')\n",
    "img_pftas = open_features_from_files('pftas')\n",
    "img_sift = open_features_from_files('sift')\n",
    "img_surf = open_features_from_files('surf')\n",
    "img_lbp = open_features_from_files('lbp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(img_ids),len(img_types),len(img_chist[0]),len(img_haralick[0]),len(img_pftas[0]),len(img_lbp[0]),len(img_surf[0]),len(img_sift[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_df():\n",
    "    df = pd.DataFrame()\n",
    "    df['ID'] = img_ids\n",
    "    df['TYPE'] = img_types\n",
    "\n",
    "    def make_columns_from_feature(feature,name,df):\n",
    "        for i in xrange(0,len(feature[0])):\n",
    "            column=[]\n",
    "            for j in xrange(0,len(feature)):\n",
    "                column.append(feature[j][i])\n",
    "            \n",
    "            column_name = str(name)+str(i+1)\n",
    "            df[column_name] = column\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    df = make_columns_from_feature(img_haralick,'HARALICK',df)\n",
    "    df = make_columns_from_feature(img_chist,'CHIST',df)\n",
    "    df = make_columns_from_feature(img_pftas,'PFTAS',df)\n",
    "    df = make_columns_from_feature(img_surf,'SURF',df)\n",
    "    df = make_columns_from_feature(img_sift,'SIFT',df)\n",
    "    df = make_columns_from_feature(img_lbp,'LBP',df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = make_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encode_category(y):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    return y\n",
    "\n",
    "def logistic_regression():\n",
    "    clf = linear_model.LogisticRegression()\n",
    "    return clf\n",
    "\n",
    "def extra_trees():\n",
    "    clf = ensemble.ExtraTreesClassifier(n_estimators=100,max_depth=10)\n",
    "    return clf\n",
    "\n",
    "def random_forest():\n",
    "    clf = ensemble.RandomForestClassifier(n_estimators=100,max_depth=10)\n",
    "    return clf\n",
    "\n",
    "def suppor_vector_classifier():\n",
    "    clf = svm.SVC(probability=True)\n",
    "    return clf\n",
    "\n",
    "models_dict = {logistic_regression():\"Logistic Regression\",suppor_vector_classifier():\"SVC\",random_forest():\"Random Forest\",extra_trees():\"Extra Trees\"}\n",
    "models= models_dict.keys()\n",
    "names = models_dict.values()\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(y_pred,y_test,clf_probs):\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    ll = log_loss(y_test,clf_probs)\n",
    "    return accuracy,ll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LDA = joblib.load('./models/LDA.pkl')\n",
    "test_x = LDA.transform(df[df.columns[2:]])\n",
    "len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ETc = joblib.load('./models/ETc.pkl') \n",
    "y_pred=ETc.predict(test_x)\n",
    "y_proba=ETc.predict_proba(test_x)\n",
    "y_pred, y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type1 = []\n",
    "type2 = []\n",
    "type3 = []\n",
    "#for i in xrange(0,len(img_ids)):\n",
    "#    result = str(img_ids[i])+'.jpg'\n",
    "#    img_ids_new.append(result)\n",
    "\n",
    "for h in xrange(0,len(y_proba)):\n",
    "    for p in xrange(0,len(y_proba[h])):\n",
    "        if p==0:\n",
    "            type1.append(y_proba[h][p])\n",
    "        elif p==1:\n",
    "            type2.append(y_proba[h][p])\n",
    "        elif p==2:\n",
    "            type3.append(y_proba[h][p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame()\n",
    "report_df['image_name']=img_ids\n",
    "report_df['Type_1']=type1\n",
    "report_df['Type_2']=type2\n",
    "report_df['Type_3']=type3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "report_df['image_name'] = report_df['image_name'].astype(int)\n",
    "report_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "report_df=report_df.sort_values(by=['image_name'], ascending=[True])\n",
    "report_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "report_df['image_name'] = map(lambda x: str(x)+'.jpg',report_df['image_name'])\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "report_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "report_df.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "df[df.columns[1]]=encode_category(df[df.columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_trans1 = lda.fit_transform(df[df.columns[2:]],df[df.columns[1]])\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_trans2 = lda.fit_transform(df[df.columns[2:]],df[df.columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "\n",
    "for i in xrange(0,len(X_trans1)):\n",
    "    x.append(X_trans1[i])\n",
    "    \n",
    "z=df[df.columns[1]]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x,z,'o',alpha=.5,c='r',ms=10.0)\n",
    "plt.title('LDA [Dimension=1]')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Coordinates')\n",
    "plt.yticks([0,1,2])\n",
    "plt.xlim(-6,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in xrange(0,len(X_trans2)):\n",
    "    x.append(X_trans2[i][0])\n",
    "    y.append(X_trans2[i][1])\n",
    "    \n",
    "\n",
    "z=df[df.columns[1]]\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.yticks([0,1,2])\n",
    "plt.ylim(-0.1,2.1)\n",
    "plt.xlim(0,8300)\n",
    "plt.title('LDA [Dimension=2]')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Coordinates')\n",
    "plt.plot(x,y,z,'.',alpha=.5,c='b',ms=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_model(model,x,y):\n",
    "    \n",
    "    clf = model\n",
    "\n",
    "    y = encode_category(y)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33,random_state=100)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    clf_probs = clf.predict_proba(x_test)\n",
    "    \n",
    "    result_list = [y_pred,y_test,clf_probs]\n",
    "\n",
    "    return result_list\n",
    "\n",
    "'''\n",
    "x = df[df.columns[2:]]\n",
    "x=X_trans2\n",
    "y = df[df.columns[1]]\n",
    "for i in xrange(0,len(models)):\n",
    "    models_result = []\n",
    "    result = check_model(models[i],x,y)\n",
    "    acc,ll=get_metrics(result[0],result[1],result[2])\n",
    "    \n",
    "    print models[i]\n",
    "    print \"\"\n",
    "    print \"logloss: \"+str(ll)\n",
    "    print \"\"\n",
    "    print \"===================\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TEST/TRAIN\n",
    "\n",
    "SVC 0.541713014461 0.989315787144\n",
    "Extra Trees 0.626622172785 0.825656416573\n",
    "Logistic Regression 0.555802743789 1.08780614121\n",
    "Random Forest 0.625880608083 0.830826543663\n",
    "\n",
    "\n",
    "\n",
    "FULL \n",
    "\n",
    "Logistic Regression 0.732958022274 0.67936808814\n",
    "Extra Trees 1.0 2.10942374679e-15\n",
    "SVC 1.0 0.0560539662167\n",
    "Random Forest 1.0 0.209240477966 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cw = []\n",
    "for i in [None,'balanced']:\n",
    "    print \"class weight = \"+str(i)\n",
    "    print \"===========================\"\n",
    "    clf = linear_model.LogisticRegression(C=1,class_weight=i)\n",
    "    y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=3)\n",
    "    proba  = cross_val_predict(clf,X_trans2,df[df.columns[1]],method='predict_proba',cv=3)\n",
    "    acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "    print \"cv:\"\n",
    "    print ll\n",
    "    print \"\"\n",
    "    cw.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = [0,5,10,13,15,20]\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Class Weight optimization')\n",
    "plt.ylabel('LogLoss')\n",
    "plt.xticks([])\n",
    "plt.plot([0,1],[cw[0]+0.005,cw[0]+0.005],label='None',lw=4)\n",
    "plt.plot([0,1],[cw[1],cw[1]], lw=4 ,label='Balanced')\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "q = map(lambda x:x+0.005,c_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c = [0.0001,0.001,0.01,0.1,1]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title('C optimization')\n",
    "plt.ylabel('LogLoss')\n",
    "plt.xlabel('C')\n",
    "plt.xlim([-0.01,0.85])\n",
    "plt.xticks([0,0.2,0.4,0.6,0.8],c)\n",
    "plt.plot(c,q,label='None',lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c_ll,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c = [0.0001,0.001,0.01,0.1,1]\n",
    "c_ll =[]\n",
    "for i in c:\n",
    "    print \"C = \"+str(i)\n",
    "    print \"===========================\"\n",
    "    clf = linear_model.LogisticRegression(C=i,class_weight=None)\n",
    "    y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=3)\n",
    "    proba  = cross_val_predict(clf,X_trans2,df[df.columns[1]],method='predict_proba',cv=3)\n",
    "    acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "    print \"Test/Train prediction result:\"\n",
    "    print ll\n",
    "    c_ll.append(ll)\n",
    "    print \"===========================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(C=1,class_weight='balanced',max_iter=100)\n",
    "res = check_model(clf,X_trans2,df[df.columns[1]])\n",
    "_ , ll = get_metrics(result[0],result[1],result[2])\n",
    "clf.fit(X_trans2,df[df.columns[1]])\n",
    "print ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "              \"class_weight\":[None,'balanced'],\n",
    "              \"C\":[0.0001,0.001,0.01,0.1,1]\n",
    "             }\n",
    "clf = linear_model.LogisticRegression(random_state=100)\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid,scoring=\"neg_log_loss\")\n",
    "grid_search.fit(X_trans2, df[df.columns[1]])\n",
    "print grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.ExtraTreesClassifier(n_estimators=100,max_depth=10, random_state=100)\n",
    "#clf = linear_model.LogisticRegression()\n",
    "#clf = svm.SVC(probability=True)\n",
    "result = check_model(clf,X_trans2,df[df.columns[1]])\n",
    "acc,ll=get_metrics(result[0],result[1],result[2])\n",
    "    \n",
    "print \"\"\n",
    "print \"logloss: \"+str(ll)\n",
    "print \"\"\n",
    "print confusion_matrix(result[0],result[1])\n",
    "print \"===================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "indexes = [None,5,10,13,15,20]\n",
    "ll_cv =[]\n",
    "ll_ncv =[]\n",
    "\n",
    "for i in indexes:\n",
    "    print \"depth = \"+str(i)\n",
    "    print \"===========================\"\n",
    "    clf = ensemble.ExtraTreesClassifier(n_estimators=100,max_depth=(i),random_state=100)\n",
    "    y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=3)\n",
    "    proba  = cross_val_predict(clf,X_trans2,df[df.columns[1]],method='predict_proba',cv=3)\n",
    "    acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "    print \"Test/Train prediction result:\"\n",
    "    print ll\n",
    "    ll_cv.append(ll)\n",
    "    print \"===========================\"\n",
    "\n",
    "    print \"Full prediction result:\"\n",
    "    clf.fit(X_trans2,df[df.columns[1]])\n",
    "    y_pred = clf.predict(X_trans2)\n",
    "    proba = clf.predict_proba(X_trans2)\n",
    "    acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "    print ll\n",
    "    ll_ncv.append(ll)\n",
    "    print \"===========================\"\n",
    "    print  \" \"\n",
    "    print  \" \"\n",
    "    print  \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = [0,5,10,13,15,20]\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Depth optimization')\n",
    "plt.ylabel('LogLoss')\n",
    "plt.xlabel('Depth')\n",
    "plt.plot(x,ll_ncv,lw=4,label = \"Train curve\")\n",
    "plt.plot(x,ll_cv,lw=4, label = \"CV curve\")\n",
    "plt.plot([10,10],[0,1.4], lw=2 ,label='Selected')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "indexes = range(0,201)\n",
    "\n",
    "accuracys = []\n",
    "log_losses= []\n",
    "for i in indexes[10::10]:\n",
    "    clf=ensemble.ExtraTreesClassifier(n_estimators=i,random_state=100,max_depth=10)\n",
    "    df[df.columns[1]]=encode_category(df[df.columns[1]])\n",
    "    y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=3)\n",
    "    proba  = cross_val_predict(clf,X_trans2,df[df.columns[1]],method='predict_proba',cv=3)\n",
    "    acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "    accuracys.append(acc)\n",
    "    log_losses.append(ll)\n",
    "\n",
    "'''acc,ll=get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "print \"\"\n",
    "print \"accuracy: \"+str(acc)\n",
    "print \"logloss: \"+str(ll)\n",
    "print \"\"\n",
    "print confusion_matrix(y_pred,df[df.columns[1]])\n",
    "print \"===================\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = indexes[10::10]\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.plot(x,log_losses, lw=4, label='CV Curve')\n",
    "plt.plot([100,100],[0.7,0.8],lw=4,label='Selected')\n",
    "plt.yticks([0.7,0.8])\n",
    "plt.title('N_estimators optimization')\n",
    "plt.ylabel('LogLoss')\n",
    "plt.xlabel('N_estimators')\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "              \"max_features\":[None,'sqrt','log2'],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"min_samples_leaf\":[1,2,3,4,5]\n",
    "             }\n",
    "clf = ensemble.ExtraTreesClassifier(max_features=None,n_estimators=100,\n",
    "                                    random_state=100,max_depth=10)\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid,scoring=\"neg_log_loss\")\n",
    "grid_search.fit(X_trans2, df[df.columns[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cw = []\n",
    "for i in [None,'balanced']:\n",
    "    print \"class weight = \"+str(i)\n",
    "    print \"===========================\"\n",
    "    clf = ensemble.ExtraTreesClassifier(max_features=None, n_estimators=100, random_state=100, max_depth=10,\n",
    "                                       criterion=\"gini\",min_samples_leaf=3,class_weight=i)\n",
    "    y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=3)\n",
    "    proba  = cross_val_predict(clf,X_trans2,df[df.columns[1]],method='predict_proba',cv=3)\n",
    "    acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "    print \"cv:\"\n",
    "    print ll\n",
    "    print \"\"\n",
    "    cw.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(C=1)#,class_weight='balanced')\n",
    "\n",
    "y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=4)\n",
    "proba = cross_val_predict(clf,X_trans2,df[df.columns[1]],method=\"predict_proba\",cv=4)\n",
    "\n",
    "acc, ll = get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "print acc,ll\n",
    "print \"\"\n",
    "print confusion_matrix(y_pred,df[df.columns[1]])\n",
    "print \"\"\n",
    "target_names = ['Type_1','Type_2','Type_3']\n",
    "print classification_report(y_pred,df[df.columns[1]],target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.ExtraTreesClassifier(n_estimators=100,random_state=100,bootstrap=False,\n",
    "                                   criterion = 'gini',max_depth=10,max_features=None,\n",
    "                                    min_samples_leaf = 2)\n",
    "\n",
    "y_pred = cross_val_predict(clf,X_trans2,df[df.columns[1]],cv=4)\n",
    "proba  = cross_val_predict(clf,X_trans2,df[df.columns[1]],method='predict_proba',cv=4)\n",
    "\n",
    "#clf.fit(X_trans2,df[df.columns[1]])\n",
    "#y_pred = clf.predict(X_trans2)\n",
    "#proba = clf.predict_proba(X_trans2)\n",
    "\n",
    "acc,ll=get_metrics(y_pred,df[df.columns[1]],proba)\n",
    "print \"\"\n",
    "print \"accuracy: \"+str(acc)\n",
    "print \"logloss: \"+str(ll)\n",
    "print \"\"\n",
    "print confusion_matrix(y_pred,df[df.columns[1]])\n",
    "print \"===================\"\n",
    "\n",
    "target_names = ['Type_1','Type_2','Type_3']\n",
    "print classification_report(y_pred,df[df.columns[1]],target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = ensemble.ExtraTreesClassifier(n_estimators=100,random_state=100,bootstrap=True,\n",
    "                                   criterion = 'gini',max_depth=10,oob_score=True,\n",
    "                                   max_features=None,min_samples_leaf = 2)\n",
    "clf.fit(X_trans2,df[df.columns[1]])\n",
    "odf = clf.oob_decision_function_\n",
    "y_pred = clf.predict(X_trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "odf,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "\n",
    "# Binarize the output\n",
    "#y = label_binarize(y_pred, classes=[0, 1, 2])\n",
    "y = label_binarize(df[df.columns[1]], classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_roc_auc(y_test,y_proba, n_classes):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    y_score = []\n",
    "        \n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i],y_proba[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "    \n",
    "    return fpr,tpr,roc_auc\n",
    "\n",
    "fpr,tpr,roc_auc = calculate_roc_auc(y,odf,n_classes)\n",
    "\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "lw = 5\n",
    "i=0\n",
    "plt.plot(fpr[i], tpr[i],linestyle='-',\n",
    "         lw=lw, label='ROC curve, class '+str(i+1)+' (area = %0.3f)' % roc_auc[i])\n",
    "plt.plot(fpr[i+1], tpr[i+1],linestyle='-',\n",
    "         lw=lw, label='ROC curve, class '+str(i+2)+' (area = %0.3f)' % roc_auc[(i+1)])\n",
    "plt.plot(fpr[i+2], tpr[i+2], color='red',linestyle='-',\n",
    "         lw=lw, label='ROC curve, class '+str(i+3)+' (area = %0.3f)' % roc_auc[(i+2)])\n",
    "plt.plot([0.182574,1],[0, 1-0.182574], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC CURVES')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "clf = ensemble.ExtraTreesClassifier(n_estimators=100,random_state=100,bootstrap=False,\n",
    "                                   criterion = 'gini',max_depth=10,\n",
    "                                   max_features=None,min_samples_leaf = 3)\n",
    "clf.fit(X_trans2,df[df.columns[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(clf, './models/ETc.pkl')\n",
    "joblib.dump(lda,'./models/LDA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ETc = joblib.load('./models/ETc.pkl') \n",
    "y_pred=ETc.predict(X_trans2)\n",
    "y_proba=ETc.predict_proba(X_trans2)\n",
    "\n",
    "acc,ll = get_metrics(y_pred,df[df.columns[1]],y_proba)\n",
    "print acc,ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LDA = joblib.load('./models/LDA.pkl')\n",
    "x_trans = LDA.transform(df[df.columns[2:]])\n",
    "x_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot([1,2,3,4,5],[0,0,0,2,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
